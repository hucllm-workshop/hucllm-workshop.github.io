---
#
# By default, content added below the "---" mark will appear in the home page
# between the top bar and the list of recent posts.
# To change the home page layout, edit the _layouts/home.html file.
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
#
layout: home
---

<!-- <img src="/images/deep.jpg"> -->
<!-- <center>
<h2 class="blackpar_title">Human-Centered Large Language Modeling Workshop </h2>
</center> -->

<p style="margin: 0px 0px 20px 0px;">

<i>A word's meaning resides in the heart and soul of its "generator" - people. How do we include human (personal, social, cultural, situational) context, ethically, into LLMs -- the base models of our NLP systems?</i>
</p>

<!-- <br><br> -->
<h2 class="blackpar_title" id="Overview">Overview</h2>

<p>

Language modeling in the context of its source (author) and target (audience) can enable NLP systems to better understand human language. Advances in human-centered NLP have established the importance of modeling the human context holistically, including personal, social, cultural, and situationa factors in NLP systems. Yet, our NLP systems have become heavily reliant on large language models that do not capture the human context. 
</p>

<p>
Human language is highly dependent on the rich and complex human context such as (a) who is speaking, (b) to whom, (c) where (situation/environment) and (d) when (time and place). It is additionally moderated by the changing human states of being such as their mental and emotional states. 
</p>

<p>
Current large language models can possibly simulate some form of human context given their large scale of parameters and pre-training data. However, they do not explicitly process language in the higher order structure of language – connecting documents to people, the "source" of the language. 
</p>

<p>
Prior work has demonstrated the benefits of including the author’s information using LLMs for downstream NLP tasks. Recent research has also shown that LLMs can benefit from including additional author context in the LM pre-training task itself. Progress in the direction of merging the two successful parallels, i.e., human-centered NLP and LLMs, drives us toward creating a vision of human-centered LLMs for the future of NLP in the era of LLMs.
</p>

<br/>


<!-- Call for Papers -->
<h2 class="blackpar_title" id="Call for Papers">Call for Papers</h2>
<p>Human-centered large language modeling has the potential to bring promising improvements in human-centric applications through multiple domains such as healthcare, education, consumerism, etc. Simultaneously, this new research focus also brings multitudes of unexplored architectural, data, technical, fairness, and ethical challenges.</p>


<p>We invite submissions on topics that include, but are not limited to:</p>
<ul>
	<li><b>Human-centered LLM training/fine-tuning</b>: Strategies to include the human context of the speaker and/or addressee, such as their personal factors, social context, etc.; Integrating group and/or individual human characteristics and traits; Human language modeling with multi-lingual LLMs or low-resource languages</li>
	<li><b>Analysis and Applications</b>: Evaluations for human language modeling that demonstrates personalized or socially contextual language understanding; Empirical findings with human language modeling demonstrating failure cases with an exhaustive analysis of negative results; Bias measurement and bias mitigation using human language modeling; Applications built on top of LLMs for real-world uses or translational impact</li>
	<li><b>Datasets</b>: Obtaining data for training and evaluating human contextualized LLM models</li>
	<li><b>Position papers</b>: Position papers on opportunities and challenges, including ethical risks</li>
</ul>

<p>With our workshop, we aim to create a platform where researchers can present rising challenges and solutions in building human-centered NLP models that bring together the ideas of human and social factors adaptation into the base LLMs of our NLP systems.</p>

<br/>
<h5>Archival Submissions</h5>
<p>Authors are invited to submit long (8 pages) or short (4 pages) papers, with unlimited pages for references and appendices. Following the ACL conference policy, authors of approved papers will be given an additional page for the final, camera-ready versions of their papers.</p>

Please ensure that the submissions are formatted according to the ACL template style. You can access the template <a href="https://github.com/acl-org/acl-style-files">here</a>.



<h5 style="margin-top: 10px;">Non-Archival Submissions</h5>

We welcome non-archival submissions through two tracks.

First, you can submit an extended abstract of work not published elsewhere, of length 2-4 pages + 2 pages for references. This can include position papers, or early stage work that would benefit from peer feedback. These submissions will also be peer-reviewed in a double-blind fashion, similar to the archival papers.

Additionally, work previously reviewed, published, or accepted to be published elsewhere can also be submitted to the non-archival track, along with details about the venue or journal where it is accepted, and a link to the archived version, if available. These papers will be reviewed in a single-blind fashion, and will be reviewed only for the fit to the workshop theme, and do not have any page limits.

Please ensure that the submissions are formatted according to the ACL template style. You can access the template <a href="https://github.com/acl-org/acl-style-files">here</a>. Accepted papers in the two non-archival tracks will be given an opportunity to present the work at the workshop, but will not be published in the ACL Anthology.

<br/>

<h4>Important Dates </h4>

<ul>
	<li>May 10 (Fri), 2024: Direct paper submission deadline</li>
	<li>May 17 (Fri), 2024: ARR commitment deadline (Submission of already ARR-reviewed papers)</li>
	<li>June 17 (Mon), 2024: Notification of acceptance</li>
	<li>July 1 (Mon), 2024: Camera-ready paper due</li>
	<li>August 15 (Thu), 2024: Workshop date</li>
</ul>

<p>All deadlines are 11:59 pm UTC -12h ("Anywhere on Earth").</p>

<br/>

<h4>Submission Links</h4>
<ul>
	<li><b>Direct Paper Submission:</b> <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/HuCLLM">https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/HuCLLM</a></li>
	<li><b>ARR Commitment Page:</b> <a href="https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/HuCLLM_ARR_Commitment">https://openreview.net/group?id=aclweb.org/ACL/2024/Workshop/HuCLLM_ARR_Commitment</a></li>
</ul>

<p>
<b>Note: All authors must have an OpenReview profile. Please ensure profiles are complete before submission.</b> As per OpenReview's moderation policy for newly created profiles:

<ul>
<li>New profiles created without an institutional email will go through a moderation process that can take up to two weeks.</li>
<li>New profiles created with an institutional email will be activated automatically.</li>
</ul>

</p>


<p>If you have any questions, please contact us at: <a href="mailto:workshophucllm@googlegroups.com">workshophucllm@googlegroups.com</a> </p>

<br/>


<h2 class="blackpar_title" id="Topics of Interest">Topics of Interest</h2>

The areas of interest include:
<ul>
	<li> LLM training/fine-tuning strategies to include the human context of the speaker and/or addressee, such as their personal factors, social context etc. </li>
    <li> LLM training integrating group and/or individual human characteristics and traits </li>
    <li> Evaluations for human language modeling that demonstrates personalized or socially contextual language understanding </li>
    <li> Bias measurement and bias mitigation using human language modeling </li>
    <li> Obtaining data for training and evaluating human contextualized LLMs models </li>
    <li> Human language modeling with multi-lingual LLMs or low-resource languages  </li>
    <li> Position papers on opportunities and challenges, including ethical risks  </li>
    <li> Empirical findings with human language modeling demonstrating failure cases with an exhaustive analysis of negative results </li>
    <li> Applications built on top of LLMs for real-world uses or translational impact  </li>
</ul>

<!-- <br><br>
<h2 class="blackpar_title">Important Dates:</h2>
<ul>
	<li>Submission Deadline: <del>September 22, 2021 AOE</del></li>
        <li>Uploading Supplementary Materials: <del>September 26, 2021 AOE</del></li>
	<li>Acceptance Notification: <del>October 23, 2021 AOE</del></li>
	<li>Camera-Ready Submission: <del>November 1, 2021 AOE</del></li>
	<li>Workshop Date: December 13, 2021</li>
</ul>
<div class="alert alert-success d-flex align-items-center" role="alert" style="font-size:20px;">
	<i class="bi bi-exclamation-triangle" style="font-size: 1.5rem; margin-right:10px;"></i>
	<div>
		The accepted papers can be found <a href="./accepted_papers.html">here</a>.
	</div>
</div>
<br><br> -->

<br/>

<!--Confirmed Speakers-->
<h2 class="blackpar_title" id="Speakers">Keynote Speakers</h2>
<div class="row_perso">
	<div class="card_perso column_perso">
	  <img src="/images/daniel_hershcovich.jpeg" alt="Daniel Hershcovich" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Daniel Hershcovich</b>
			<br>
			University of Copenhagen, Denmark
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/snigdha_chaturvedi.jpeg" alt="Snigdha Chaturvedi" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Snigdha Chaturvedi</b>
			<br>
			University of North Carolina at Chapel Hill, USA
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/sebastian_ruder.jpeg" alt="Sebastian Ruder" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Sebastian Ruder</b>
			<br>
			Google, Germany
		</h6>
		</center>
	  </div>
	</div>
</div>

<!--Panelists-->
<h2 class="blackpar_title" id="Panelists">Panelists</h2>
<div class="row_perso">
	<!-- <div class="card_perso column_perso">
	  <img src="/images/maarten_sap.jpeg" alt="Maarten Sap" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Maarten Sap</b>
			<br>
			Carnegie Mellon University, USA
		</h6>
		</center>
	  </div>
	</div> -->
	<div class="card_perso column_perso">
	  <img src="/images/Carolyn1.jpg" alt="Carolyn Rosé" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Carolyn Rosé</b>
			<br>
			Carnegie Mellon University, USA
		</h6>
		</center>
	  </div>
	</div>

	<div class="card_perso column_perso">
	  <img src="/images/kayla_jordan.jpeg" alt="Kayden Jordan" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Kayden Jordan</b>
			<br>
			Harrisburg University of Science and Technology, USA
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/debora_nozza.jpeg" alt="Debora Nozza" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Debora Nozza</b>
			<br>
			Bocconi University, Italy
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/diyi_yang.jpeg" alt="Diyi Yang" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Diyi Yang</b>
			<br>
			Stanford University, USA
		</h6>
		</center>
	  </div>
	</div>
</div>

<div class="row_perso">
	<div class="card_perso column_perso">
	  <img src="/images/sebastian_ruder.jpeg" alt="Sebastian Ruder" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Sebastian Ruder</b>
			<br>
			Google, Germany
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/sara_hooker.jpeg" alt="Sara Hooker" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b>Sara Hooker</b>
			<br>
			Cohere AI, USA
		</h6>
		</center>
	  </div>
	</div>
</div>


<h2 class="blackpar_title" id="Schedule">Tentative Schedule</h2>
<table>
  <tr>
  <th>Time</th>
  <th>Schedule</th>
  </tr>
  <tr>
  <td>9:00 - 10:00</td>
  <td>Keynote Prof. Daniel Hershcovich (UCPH): <i>Cross-cultural alignments in LLMs</i></td>
  </tr>
    <tr>
  <td>10:00 - 11:00</td>
  <td>Poster session 1</td>
  </tr>
  <tr>
  <td>11:00 - 12:00</td>
  <td>Paper presentation slots 1</td>
  </tr>
  <tr>
  <td>12:00 - 13:00</td>
  <td>Lunch break</td>
  </tr>
  <tr>
  <td>13:00 - 14:00</td>
  <td>Keynote Dr. Sebastian Ruder (Google): <i>Building Multilingual LLMs for User-centric Applications</i></td>
  </tr>
  <tr>
  <td>14:00 - 15:00</td>
  <td>Paper presentation slots 2</td>
  </tr>
  <tr>
  <td>15:30 - 16:30</td>
  <td>Keynote Prof. Snigdha Chaturvedi (UNCC): <i>Socially-aware NLP</i></td>
  </tr>
  <tr>
  <td>16:30 - 17:30</td>
  <td>Panel discussion:  including following topics: <i>Where are human-centered LLMs important? How to achieve the vision of human-centered LLMs? Which ethical issues to keep in mind while creating human-centered LLMs?</i></td>
  </tr>
</table>


<h2 class="blackpar_title" id="Organizers">Organizers</h2>
<div class="row_perso">
	<div class="card_perso column_perso">
	  <img src="/images/nikita_soni.jpeg" alt="Nikita Soni" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:nisoni@cs.stonybrook.edu">Nikita Soni</a></b>
			<br>
			Stony Brook University, USA
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/lucie_flek.jpeg" alt="Lucie Flek" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:flek@bit.uni-bonn.de">Lucie Flek</a></b>
			<br>
			University of Bonn, Germany
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/ashish_sharma.jpeg" alt="Ashish Sharma" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:ashshar@cs.washington.edu">Ashish Sharma</a></b>
			<br>
			University of Washington, USA
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/diyi_yang.jpeg" alt="Diyi Yang" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:diyiy@cs.stanford.edu">Diyi Yang</a></b>
			<br>
			Stanford University, USA
		</h6>
		</center>
	  </div>
	</div>
</div>
<div class="row_perso">
	<div class="card_perso column_perso">
	  <img src="/images/sara_hooker.jpeg" alt="Sara Hooker" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:sarahooker@cohere.com">Sara Hooker</a></b>
			<br>
			Cohere AI, USA
		</h6>
		</center>
	  </div>
	</div>
	<div class="card_perso column_perso">
	  <img src="/images/andrew_schwartz.jpeg" alt="H Andrew Schwartz" class="img_card_perso">
	  <div class="container_perso">
		<center>
		<h6>
			<b><a href="mailto:has@cs.stonybrook.edu">H Andrew Schwartz</a></b>
			<br>
			Stony Brook University, USA
		</h6>
		</center>
	  </div>
	</div>
</div>


<!-- Program Committee -->
<h2 class="blackpar_title" id="Committee">Program Committee</h2>
<ul>
	<li>Amanda Curry, Bocconi University, Italy</li>
	<li>Barbara Plank, LMU Munich, Germany</li>
	<li>Cesa Salaam, Howard University, USA</li>
	<li>Chia-Chien Hung, NEC Labs Europe, Germany</li>
	<li>Dan Goldwasser, Purdue University, USA</li>
	<li>Daniel Preotiuc-Pietro, Bloomberg, USA</li>
	<li>Debora Nozza, Bocconi University, Italy</li>
	<li>Francesco Barbieri, Snap Research, USA</li>
	<li>Gavin Abercombie, Heriot-Watt University, Scotland</li>
	<li>Giuseppe Attanasio, Bocconi University, Italy</li>
	<li>Harmanpreet Kaur, University of Michigan, USA</li>
	<li>Hye Sun Yun, Northeastern University, USA</li>
	<li>Ian Stewart, Pacific Northwest National Laboratory, USA</li>
	<li>Inna Lin, University of Washington, USA</li>
	<li>Jaemin Cho, University of North Carolina Chapel Hill, USA</li>
	<li>Jielin Qiu, Carnegie Mellon University, USA</li>
	<li>Joan Plepi, University of Marburg, Germany</li>
	<li>Kokil Jaidka, National University of Singapore</li>
	<li>Lucy Li, University of California, Berkeley, USA</li>
	<li>Lucy Lu Wang, University of Washington, USA</li>
	<li>Lyle Ungar, University of Pennsylvania, USA</li>
	<li>Maarten Sap, Carnegie Mellon University, USA</li>
	<li>Maria Antoniak, Allen Institute for AI, USA</li>
	<li>Matthias Orlikowski, Bielefeld University, Germany</li>
	<li>Meryem M'hamdi, University of Southern California, USA</li>
	<li>Monica Munnangi, Northeastern University, USA </li>
	<li>Salvatore Giorgi, University of Pennsylvania, USA</li>
	<li>Sherry Tongshuang Wu, Carnegie Mellon University, USA</li>
	<li>Shijia Liu, Northeastern University, USA   </li>
	<li>Shiran Dudy, Northeastern University, USA</li>
	<li>Shreya havaldar, University of Pennsylvania, USA</li>
	<li>Silvio Amir, Northeastern University, USA</li>
	<li>Tal August, Allen Institue for AI, USA</li>
	<li>Vivek Kulkarni, University of California, Santa Barbara, USA</li>
	<li>Zeerak Talat, Independent Researcher</li>
</ul>


<!-- <br><br>
<h2 class="blackpar_title">Sponsor</h2>
<center>
	<img src="/images/logos.png">
	
</center> -->
